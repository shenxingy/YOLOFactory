# YOLO Factory

This project provides a standardized template for fine-tuning and deploying YOLOv8 models. It features flexible, command-line-driven scripts for handling training and inference tasks, complete with performance optimizations and debugging capabilities.

## Table of Contents

  - [Features](https://www.google.com/search?q=%23features)
  - [Project Structure](https://www.google.com/search?q=%23project-structure)
  - [Setup](https://www.google.com/search?q=%23setup)
  - [How to Use](https://www.google.com/search?q=%23how-to-use)
      - [Model Training](https://www.google.com/search?q=%23model-training)
      - [Model Inference](https://www.google.com/search?q=%23model-inference)
  - [Training Script Arguments (`train.py`)](https://www.google.com/search?q=%23training-script-arguments-trainpy)
  - [Inference Script Arguments (`predict.py`)](https://www.google.com/search?q=%23inference-script-arguments-predictpy)
  - [License](https://www.google.com/search?q=%23license)

## Features

  - **Modular Scripts**: Clean separation of logic for training (`train.py`) and inference (`predict.py`).
  - **Flexible Configuration**: Easily configure models, datasets, hyperparameters, and hardware via command-line arguments.
  - **Performance Optimizations**: Supports multi-threaded data loading (`--workers`) and in-memory caching (`--cache-data`) to accelerate training.
  - **Rapid Debugging**: Includes a `--fraction` argument to train on a small subset of the dataset, perfect for quickly verifying the pipeline.
  - **Organized Structure**: A standardized directory layout for datasets, experiment runs, logs, and weight files.

## Project Structure

Below is the directory structure for this project:

```
.
├── datasets/
│   └── TESIS/
│       └── data.yaml      # Dataset configuration file
├── runs/
│   ├── train/             # Stores all training output
│   │   ├── DEBUG_RUN/     # Example of a debug run
│   │   └── FULL_RUN/      # Example of a full training run
│   └── predict/           # Stores all inference output
├── weights/               # (Optional) For custom or downloaded pre-trained weights
├── train.py               # Core model training script
├── predict.py             # Core model inference script
├── train.sh               # (Example) Training execution script
├── run_predict.sh         # (Example) Inference execution script
├── README.md              # This file
└── LICENSE                # Project license
```

  - `datasets/`: Contains your datasets. Each dataset should have a `data.yaml` file defining paths to the training/validation sets and class information.
  - `runs/`: Automatically generated by Ultralytics to save all experiment results, including weights, logs, and various evaluation charts.
  - `train.py`: The primary script for launching model training.
  - `predict.py`: The primary script for running object detection with a trained model.
  - `*.sh` files: Bash scripts providing convenient shortcuts for executing common commands.

## Setup

1.  **Clone the Repository**

    ```bash
    git clone <your-repo-url>
    cd <your-repo-name>
    ```

2.  **Create and Activate a Python Environment** (Recommended)

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install Dependencies**
    This project primarily depends on `ultralytics`. Install it via pip:

    ```bash
    pip install ultralytics
    ```

4.  **Prepare Your Dataset**

      - Place your dataset inside the `datasets/` directory.
      - Ensure the paths in your `data.yaml` file are correct. A typical `data.yaml` looks like this:
        ```yaml
        train: ../images/train
        val: ../images/val

        # number of classes
        nc: 8

        # class names
        names: ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8']
        ```

5.  **Download Pre-trained Models** (If needed)
    The script will automatically download standard YOLOv8 models (e.g., `yolov8s.pt`). If you are using custom pre-trained weights, place them in the `weights/` directory.

## How to Use

### Model Training

Use the `train.py` script to fine-tune a model. All parameters can be configured via the command line.

**Example 1: Full Training Session**

This command fine-tunes the `yolov8s.pt` model on the dataset specified in `data.yaml` for 50 epochs.

```bash
python train.py \
    --model-name 'yolov8s.pt' \
    --data-config 'datasets/TESIS/data.yaml' \
    --epochs 50 \
    --batch-size 16 \
    --img-size 640 \
    --workers 8 \
    --cache-data \
    --project-name 'runs/train' \
    --run-name 'TESIS_yolov8s_full_run_01' \
    --device '0'
```

**Example 2: Quick Debugging Session**

This command uses only 10% of the data to train for 5 epochs. It's ideal for verifying that the entire process works correctly before launching a full training run.

```bash
python train.py \
    --model-name 'yolov8n.pt' \
    --data-config 'datasets/TESIS/data.yaml' \
    --epochs 5 \
    --fraction 0.1 \
    --project-name 'runs/train' \
    --run-name 'debug_run_10_percent'
```

After training, the best (`best.pt`) and last (`last.pt`) weights will be saved in `runs/train/<run-name>/weights/`.

### Model Inference

Use the `predict.py` script with your trained weights (`.pt` file) to make predictions on new images or videos.

**Example: Inference on a Single Image**

This command loads your best-trained weights, runs prediction on `path/to/your/image.jpg`, and saves the annotated result in `runs/predict/latest_run/`.

```bash
python predict.py \
    --weights 'runs/train/TESIS_yolov8s_full_run_01/weights/best.pt' \
    --source 'path/to/your/image.jpg' \
    --output-dir 'runs/predict' \
    --conf-thres 0.4 \
    --save
```

**Key Inference Arguments**:

  - `--weights`: **Required**. Path to your trained model weights file.
  - `--source`: **Required**. Path to the input source (can be an image, a video, or a folder of images).
  - `--save`: If included, the output image/video with bounding boxes will be saved.

## Training Script Arguments (`train.py`)

| Argument | Default Value | Description |
| :--- | :--- | :--- |
| `--model-name` | `yolov8s.pt` | Pre-trained model name or path to start from. |
| `--data-config`| `datasets/TESIS/data.yaml`| Path to the dataset configuration YAML file. |
| `--epochs` | `50` | Total number of training epochs. |
| `--batch-size` | `-1` | Batch size for training. Use `-1` for auto-batch. |
| `--img-size` | `640` | Input image size for training. |
| `--workers` | `8` | Number of worker threads for data loading. |
| `--cache-data` | `(flag)` | Cache dataset images in RAM to accelerate training. |
| `--fraction` | `1.0` | Fraction of the dataset to use for training (e.g., `0.1` for 10%). |
| `--project-name`| `runs/train` | Root directory to save training runs. |
| `--run-name` | `TESIS_yolov8s` | Specific name for this training run. |
| `--device` | `None` | Device to run on, e.g., `"0"`, `"0,1"`, or `"cpu"`. |

## Inference Script Arguments (`predict.py`)

| Argument | Required? | Default Value | Description |
| :--- | :--- | :--- | :--- |
| `--weights` | **Yes** | - | Path to the trained model weights file (`.pt`). |
| `--source` | **Yes** | - | Path to the input source (image, video, or folder). |
| `--output-dir`| No | `runs/predict`| Directory to save prediction results. |
| `--save` | No | `(flag)` | Save the output images/videos with annotations. |
| `--conf-thres`| No | `0.4` | Confidence threshold for detections. |
| `--device` | No | `None` | Device to run on, e.g., `"0"`, `"0,1"`, or `"cpu"`. |
| `--hide-labels`| No | `(flag)` | Hide class labels on the output. |
| `--hide-conf` | No | `(flag)` | Hide confidence sco◊res on the output. |

## License

This project is licensed under the [MIT License](https://www.google.com/search?q=LICENSE).